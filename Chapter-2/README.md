Working with text data

- preparing text for large language model training
- Splitting text into word and subword tokens
- Byte pair encoding as a more advanced way of 
tokenizing text
- Sampling training examples with a sliding window 
approach
- Converting tokens into vectors that feed into a 
large language model